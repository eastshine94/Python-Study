# 핸즈온 머신러닝(사이킷런과 텐서플로를 활용한 머신러닝, 딥러닝 실무)
[![book](http://www.hanbit.co.kr/data/books/B9267655530_l.jpg)](http://www.hanbit.co.kr/store/books/look.php?p_code=B9267655530)

# ch1. 한눈에 보는 머신러닝

# 1.1 머신러닝이란
머신러닝은 데이터로부터 학습하도록 컴퓨터를 프로그래밍하는 과학(또는 예술)

# 1.2 왜 머신러닝을 사용하는가?

스팸 필터를 예시로 할 때,  
전통적인 접근 방법에서는 문제가 단순하지 않아 규칙이 점점 길고 복잡해지므로 유지 보수하기 매우 힘들어짐  
반면 머신러닝 기법에 기반을 둔 스팸 필터는 일반 메일에 비해 스팸에 자주 나타나는 패턴을 감지하여  
어떤 단어와 구절이 스팸 메일을 판단하는 데 좋은 기준인지 자동으로 학습한다.  

머신러닝은 다음 분야에 뛰어남.  
- 기존 솔루션으로는 많은 수동 조정과 규칙이 필요한 문제
+ 전통적인 방식으로는 전혀 해결 방법이 없는 복잡한 문제
+ 유동적인 환경 : 머신러닝 시스템은 새로운 데이터에 적응할 수 있다.
+ 복잡한 문제와 대량의 데이터에서 통찰 얻기

# 1.3 머신러닝 시스템의 종류

- 사람의 감독 하에 훈련하는 것인지 그렇지 않은 것인지(지도, 비지도, 강화 학습)
- 실시간으로 점진적인 학습을 하는지 아닌지(온라인 학습과 배치 학습)
- 단순하게 알고 있는 데이터 포인트와 새 데이터 포인트를 비교하는 것인지  
  아니면 훈련 데이터셋에서 과학자들처럼 패턴을 발견하여 예측 모델을 만드는지(사례 기반 학습과 모델기반 학습)

## 1.3.1 지도학습과 비지도 학습
### 지도학습(supervised learning)
지도학습에는 알고리즘에 주입하는 훈련 데이터에 레이블(label)이라는 원하는 답이 포함  
ex) classification(스팸 필터), regression(예측 변수(주행거리,연식,브랜드 등)를 이용해 타깃 수치(중고차 가격)를 예측)  

### 비지도 학습(unsupervised learning)
비지도학습에는 훈련 테이터에 레이블이 없다. 시스템이 아무런 도움 없이 학습  
다음과 같은 비지도 학습 알고리즘이 있다.  
+ 군집(clustering)
    * k-Means
    * 계층 군집 분석(Hierarchical Cluster Analysis, HCA)
    * 기댓값 최대화(Expectation Maximization)
+ 시각화(visualization)와 차원 축소(dimensionality reduction)
    * 주성분 분석(PCA)
    * 커널 PCA
    * 지역적 선형 임베딩(Locally-Linear Embedding, LLE)
    * t-SNE(t-distributed Stochastic Neighbor Embedding)
+ 연관 규칙 학습(Association rule learning)
    * Apriori
    * Eclat
    
### 준지도 학습(semisupervised learning)
준지도학습은 레이블이 없는 데이터가 많고 레이블이 있는 데이터가 조금 일 때 학습  

### 강화 학습(Reinforcement Learning)
학습하는 시스템을 **에이전트**라고 부르며 환경을 관찰해서 행동(action)을 실행하고 그 결과로 보상(reward) 또는 벌점(penalty)을 받는다.  
시간이 지나면서 가장 큰 보상을 얻기위해 **정책(policy)** 이라고 부르는 최상의 전략을 스스로 학습  
정책은 주어진 상황에서 에이전트가 어떤 행동을 선택해야 할지 정의한다.  

## 1.3.2 배치 학습과 온라인 학습
머신러닝 시스템을 분류하는 데 사용하는 다른 기준은 입력 데이터의 스트림(stream)으로부터 점진적으로 학습할 수 있는지 여부이다.  

### 배치학습(batch learning)
**배치 학습** 에서는 시스템이 점진적으로 학습할 수 없다. 가용한 데이터를 모두 사용해 훈련  
먼저 시스템을 훈련시키고 그런 다음 제품 시스템에 적용하면 더 이상의 학습 없이 실행된다. 즉, 학습한 것을 단지 적용만 한다.  
이를 **오프라인 학습(offline learning)** 이라고 한다.  
배치 학습 시스템이 새로은 데이터에 대해 학습하려면 전체 데이터를 사용하여 시스템의 새로운 버전을 처음부터 다시 훈련해야 한다.  
이 방식은 시간과 컴퓨팅 자원을 많이 소모하게 된다.  
자원이 제한된 시스템(예를 들면 화성 탐사 로버)이 스스로 학습해야 할 떄 많은 양의 훈련 데이터르 나르고 학습을 위해 매일 몇 시간씩 많은 자원을 사용하면 심각한 문제가 발생할 수 있다. 이런 경우에는 점진적으로 학습할 수 있는 알고리즘을 사용하는 편이 낫다.  

### 온라인 학습(online learning)
온라인 학습에서는 데이터를 순차적으로 한 개씩 또는 **미니배치(mini-bacth)** 라 부르는 작은 묶음 단위로 주입하여 시스템을 훈련  
매 학습 단계가 빠르고 비용이 적게 들어 시스템은 데이터가 도착하는 대로 즉시 학습할 수 있다.  
이 경우 전체 프로세스는 보통 오프라인으로 실행(즉, 실시간 시스템에서 수행되는 것이 아니다.)   
따라서 점진적 학습(incremental learning)이라고 생각하자.  
**학습률(learning rate)** 는 변화하는 데이터에 얼마나 빠르게 적응할 것인지를 나타냄  
학습률을 높게 하면 시스템이 데이터에 빠르게 적응하지만 예전 데이터를 금방 잊어버린다.  
학습률이 낮으면 느리게 학습되지만 새로운 데이터에 있는 잡음이나 대표성이 없는 데이터 포인트에 덜 민감해짐  

온라인 학습에서 가장 큰 문제점은 시스템에 나쁜 데이터가 주입되었을 때 시스템 성능이 점진적으로 감소한다는 것  
이러한 문제를 해결하려면  
면밀한 모니터링하고 성능 감소가 감지되면 즉시 학습 중지 또는  
입력 데이터를 모니터링해서 비정상 데이터를 잡아낸다.(이상치 탐지 알고리즘 사용)

## 1.3.3 사례 기반 학습과 모델 기반 학습
머신러닝 시스템은 어떻게 일반화되는가에 따라 분류할 수도 있다.  
주어진 훈련 데이터로 학습하지만 훈련 데이터에서는 본 적 없는 새로운 데이터로 일반화되어야 한다.  

### 사례 기반 학습(instance-based learning)
사례기반학습은 시스템이 사례를 기억함으로써 학습한다.  
그리고 유사도 측정을 사용해 새로운 데이터에 일반화한다.  
예를 들어 스팸이냐 아니냐를 예측할 때 스팸 메일과 공통으로 가지고 있는 단어가 많으면 스팸으로 분류한다.  

### 모델 기반 학습(model-based learning)
모델 기반 학습은 샘플들의 모델을 만들어 예측에 사용한다.  
모델의 예시로는 linear regression, logistic regression 등등이 있다.  
작업의 흐름은 다음과 같다.  
- 데이터를 분석한다.
- 모델을 선택한다.
- 훈련 데이터로 모델을 훈련시킨다.(즉, 학습 알고리즘이 비용함수를 최소화하는 모델 파라미터를 찾는다)
- 새로운 데이터에 모델을 적용해 예측을 하고 이 모델이 잘 일반화 됐는지 확인한다.  

# 1.4 머신러닝의 주요 도전 과제

## 1.4.1 충분하지 않은 양의 훈련 데이터
대부분의 머신러닝 알고리즘이 잘 작동하려면 데이터가 많아야 한다.  
아주 간단한 모델을 포함하여 여러 다른 머신러닝 알고리즘에 충분한 데이터가 주어지면 복잡한 자연어 중의성 해소 문제를 거의 비슷하게 처리한다.  
복잡한 문제에서 알고리즘보다 데이터가 더 중요할 수 있다.  
하지만 작거나 중간 규모의 데이터셋이 여전히 매우 흔하고, 훈련 데이터를 추가로 모으는 것이 항상 쉽거나 저렴한 일은 아니므로, 아직은 알고리즘도 중요하다.

## 1.4.2 대표성이 없는 훈련 데이터
일반화가 잘되려면 일반화하기 원하는 새로운 사례를 훈련 데이터가 잘 대표하는 것이 중요하다.  
샘플이 작으면 **샘플링 잡음(sampling noise)** 즉, 우연에 의한 대표성 없는 데이터가 생긴다.  
매우 큰 샘플도 표본 추출 방법이 잘못되면 대표성을 띠지 못할 수 있는데 이를 **샘플링 편향(sampling bias)** 이라고 한다.

## 1.4.3 낮은 품질의 데이터
훈련 데이터가 에러, 이상치, 잡음(예를 들면 성능이 낮은 측정 장치 때문에)으로 가득하다면 머신러닝 시스템이 내재된 패턴을 찾기 어려워 잘 작동하지 않는다. 그렇기 때문에 훈련 데이터 정제에 시간을 투자해야 한다. 예를 들어  

- 일부 샘플이 이상치라는 게 명확하면 간단히 그것을 무시하거나 수동으로 잘못된 것을 고치는 것이 좋다
- 일부 샘플에 특성 몇 개가 빠져있다면(예를 들면 고객 중 몇몇이 나이를 기록하지 않음), 이 특성를 모두 무시할지, 이 샘플을 무시할지, 빠진 값을 채울지(예를 들면 평균나이로), 또는 이 특성을 넣은 모델과 제외한 모델을 따로 훈련시킬 것인지 등을 정해야 한다.

## 1.4.4 관련 없는 특성 
성공적으로 머신 러닝을 하기 위해선 훈련에 사용할 좋은 특성들을 찾아야 한다.  
이 과정을 특성 공학(feature engineering)이라 하며 다음 작업을 포한한다.  
- **특성 선택(feature selection)** : 가지고 있는 특성 중에서 훈련에 가장 유용한 특성을 선택
- **특성 추출(feature extraction)** : 특성을 결합하여 더 유용한 특성을 만든다.
- 새로운 데이터를 수집해 새 특성을 만든다.

## 1.4.5 훈련 데이터 과대적합(Overfitting)
과대 적합은 훈련 데이터에 있는 잡음의 양에 비해 모델이 너무 복잡할 떄 일어난다. 해결 방법은 다음과 같다.  
- 파라미터 수가 적은 모델을 선택하거나(예를 들면 고차원 다항 모델보다 선형 모델),  
  훈련 데이터에 있는 특성 수를 줄이거나, 모델에 제약을 가하여 단순화 시킨다.
- 훈련 데이터를 더 많이 모은다.
- 훈련 데이터의 잡음을 줄인다.(예를 들면 오류 데이터 수정과 이상치 제거)

모델을 단순하게 하고 과대적합의 위험을 감소시키기 위해 모델에 제약을 가하는 것을 **규제(regularization)** 라고 한다  
학습하는 동안 적용할 규제의 양은 **하이퍼파라미터(hyperparameter)** 가 결정한다.  
하이퍼파라미터는 모델이 아니라 학습 알고리즘의 파라미터이다. 
그래서 학습 알고리즘으로부터 영향을받지 않으며, 훈련 전에 미리 지정되고, 훈련하는 동안에는 상수로 남아 있는다.  
따라서 머신러닝 시스템을 구축할 때 이 하이퍼파라미터 튜닝은 매우 중요한 과정이다.  

## 1.4.6 훈련 데이터 과소적합(underfitting) 
모델이 너무 단순해서 데이터의 내재된 구조를 학습하지 못할 때 일어난다.  
즉, 현실이 모델보다 더 복잡하여 훈련 샘플에서조차도 부정확한 예측을 만들어 내는 것이다.  
이 문제를 해결하는 주요 기법은 다음과 같다.  
- 파라미터가 더 많은 강력한 모델을 선택한다.
- 학습 알고리즘에 더 좋은 특성을 제공한다. 
- 모델의 제약을 줄인다.(예를 들면 규제 하이퍼파라미터를 감소시킨다.)

# 1.5 테스트와 검증
훈련 데이터를 train set와 test set으로 나눈다.  
새로운 샘플에 대한 오류 비율을 **일반화 오차(generalization error)** 라고 하며, test set에서 모델을 평가함으로써 이 오차에 대한 추정값(estimation)을 얻는다.  
훈련 오차가 낮지만 일반화 오차가 높다면 이는 모델이 훈련 데이터에 과대적합 되었다는 뜻이다.  
train set과 test set만을 이용하여 하이퍼파라미터를 최적화할 시에 일반화 오차를 test set에서 여러 번 측정했으므로 모델과 하이퍼파라미터가 test set에 최적화 된 모델이 만들어 지게 된다. 이는 모델이 새로운 데이터에 잘 작동하지 않을 수 있다는 뜻이다.  
이 문제를 해결하기 위해 validation set를 만든다.  
train set를 사용해 다양한 하이퍼파라미터로 여러 모델을 훈련시키고, validation set에서 최상의 성능을 내는 모델과 하이퍼 파라미터를 선택한다.  
만족스러운 모델을 찾으면 일반화 오차의 추정값을 얻기 위해 test set로 단 한 번의 최종 테스트를 한다.  

훈련 데이터에서 validation set로 너무 많은 데이터를 뺏기지 않기 위해 일반적으로 교차검증(cross-validation) 기법을 사용한다.  
교차 검증은 train set를 여서 subset으로 나누고 각 모델을 이 subset의 조합으로 훈련 시키고 나머지 부분으로 검증한다.  
모델과 하이퍼파라미터가 선택되면 전체 훈련 데이터를 사용하여 선택한 하이퍼파라미터로 최종 모델을 훈련시키고 test set에서 일반화 오차를 측정한다.

# 1.6 요약
- 머신러닝은 명시적인 규칙을 코딩하지 않고 기계가 데이터로부터 학습하여 어떤 작업을 더 잘하도록 만드는 것이다.
- 여러 종류의 머신러닝 시스템이 있다. 지도학습과 비지도 학습, 배치학습과 온라인 학습, 사례 기반 학습과 모델 기반 학습 등
- 머신러닝 프로젝트에서 train set에 데이터를 모아 학습 알고리즘에 주입한다. 학습 알고리즘이 모델 기반이면 train set에 모델을 맞추기 위해 파라미터를 조정하고(즉, train set에서 좋은 예측을 만들기 위해), 새로운 데이터에서도 좋은 예측을 만들거라 기대한다.   
  알고리즘이 사례 기반이면 샘플을 기억하는 것이 학습이고 새로운 샘플에 일반화하기 위해 유사도 측정을 사용한다.
- train set가 너무 작거나, 대표성이 없는 데이터이거나, 잡음이 많고 관련 없는 특성으로 오염되어 있다면 시스템이 잘 작동하지 않는다. 
  그리고, 모델이 너무 단순하거나(과소적합된 경우) 너무 복잡하지 않아야 한다.(과대적합된 경우)
- 모델이 새로운 샘플에 잘 일반화 될지 확인하기 위해 훈련 데이터를 train set, validation set, test set으로 나눈 뒤, train set를 사용해 다양한 하이퍼파라미터로 여러 모델을 훈련시키고, validation set에서 최상의 성능을 내는 모델과 하이퍼 파라미터를 선택한다. 최적의 모델을 찾으면 test set로 단 한 번의 최종 테스트를 한다.  

### 참고 자료  
오렐리앙 제롱(Aurélien Géron), 핸즈온 머신러닝, 1판, 한빛미디어(주), 2018
